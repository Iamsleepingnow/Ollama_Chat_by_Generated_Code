import json
import random
import time
import atexit
import os
import ollama
import gradio as gr
from datetime import datetime
import webbrowser
import shutil

# é»˜è®¤æ¨¡å‹é…ç½®ä¿¡æ¯ï¼ˆå‚è€ƒï¼‰ä¸€èˆ¬æƒ…å†µä¸‹ä¼šè¢«./Configs.jsonè¦†ç›–
configs = {
    # IPåœ°å€
    "host": "127.0.0.1",
    # ç«¯å£å·
    "port": "11434",
    # UIç«¯å£
    "uiport": "7866",
    # æ¨¡å‹åç§°
    "model_name": "qwq-7b",
    # æ¨¡å‹å‚æ•°é€‰é¡¹
    "options": {
        "temperature": 1.0,  # temperatureå€¼è¶Šé«˜ï¼Œæ¨¡å‹åˆ›é€ æ€§è¶Šå¼ºï¼›å€¼è¶Šä½ï¼Œæ¨¡å‹ç›¸å¹²æ€§è¶Šå¼ºã€‚å€¼1ä¸ºé»˜è®¤å€¼ã€‚
        "num_ctx": 4096,  # num_ctxæ˜¯ä¸Šä¸‹æ–‡æœ€å¤§tokenæ•°é‡ï¼Œé»˜è®¤ä¸º4096ã€‚
        "top_k": 50,  # top_ké‡‡æ ·ä¼šå½±å“å›ç­”çš„å¤šæ ·åŒ–ç¨‹åº¦ï¼Œæ¨èèŒƒå›´10~100ï¼Œé»˜è®¤40ã€‚
        "top_p": 0.9,  # top_Pç›¸å½“äºtop_Kçš„é˜ˆå€¼ï¼Œä¹Ÿä¼šå½±å“å¤šæ ·åŒ–ç¨‹åº¦ï¼Œæ¨èèŒƒå›´0.5~0.95ï¼Œé»˜è®¤0.9ã€‚
        "repeat_penalty": 1.2,  # repeat_penaltyæ˜¯é‡å¤æƒ©ç½šï¼Œèƒ½é¿å…ç”Ÿæˆé‡å¤ä¿¡æ¯ï¼Œæ¨èèŒƒå›´0.9~1.5ï¼Œé»˜è®¤1.1ã€‚
        "seed": -1  # seedæ˜¯ä½¿ç”¨å›ºå®šç§å­ï¼Œ-1ä¸ºä½¿ç”¨éšæœºç§å­ã€‚
    }
}

# é»˜è®¤ç³»ç»Ÿæç¤ºè¯å’ŒåŠ©æ‰‹ç¬¬ä¸€å¥è¯
DEFAULT_SYSTEM_PROMPT = "## Role:\næˆ‘æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘ç²¾é€šå¤šå›½è¯­è¨€ï¼Œå¯¹ç§‘å­¦ã€æ–‡å­¦ã€å†å²ã€æ•°å­¦ã€å“²å­¦ã€è‰ºæœ¯ç­‰æ–‡åŒ–é¢†åŸŸäº†å¦‚æŒ‡æŒã€‚è¯·å‘Šè¯‰æˆ‘ä½ çš„éœ€æ±‚ï¼Œæˆ‘éƒ½èƒ½å°½æˆ‘æ‰€èƒ½åœ°æ‰§è¡Œå¹¶ç»™å‡ºå»ºè®®ã€‚"
DEFAULT_ASSISTANT_FIRST_PROMPT = "æˆ‘æ˜¯ä½ çš„å°åŠ©æ‰‹ï¼Œä½ å¯ä»¥å«æˆ‘å°åŠ©ï¼Œæœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å—ï¼ŸğŸ˜‹"

# åŠ è½½é…ç½®
def load_config():
    config_file = './Configs.json'
    if os.path.exists(config_file):
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                conf = json.load(f)
                configs.update(conf)
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(configs, f, indent=4, ensure_ascii=False)
    else:
        print("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤é…ç½®")
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(configs, f, indent=4, ensure_ascii=False)

# åŠ è½½ç³»ç»Ÿæç¤ºè¯
def load_system_prompt():
    system_prompt_file = './SystemPrompt.md'
    if os.path.exists(system_prompt_file):
        try:
            with open(system_prompt_file, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"åŠ è½½ç³»ç»Ÿæç¤ºè¯å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
            with open(system_prompt_file, 'w', encoding='utf-8') as f:
                f.write(DEFAULT_SYSTEM_PROMPT)
            return DEFAULT_SYSTEM_PROMPT
    else:
        print("ç³»ç»Ÿæç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤æç¤ºè¯")
        with open(system_prompt_file, 'w', encoding='utf-8') as f:
            f.write(DEFAULT_SYSTEM_PROMPT)
        return DEFAULT_SYSTEM_PROMPT

# åŠ è½½åŠ©æ‰‹ç¬¬ä¸€å¥è¯
def load_assistant_first_prompt():
    assistant_first_prompt_file = './AssistantFirstPrompt.md'
    if os.path.exists(assistant_first_prompt_file):
        try:
            with open(assistant_first_prompt_file, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"åŠ è½½åŠ©æ‰‹ç¬¬ä¸€å¥è¯å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
            with open(assistant_first_prompt_file, 'w', encoding='utf-8') as f:
                f.write(DEFAULT_ASSISTANT_FIRST_PROMPT)
            return DEFAULT_ASSISTANT_FIRST_PROMPT
    else:
        print("åŠ©æ‰‹ç¬¬ä¸€å¥è¯æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤æç¤ºè¯")
        with open(assistant_first_prompt_file, 'w', encoding='utf-8') as f:
            f.write(DEFAULT_ASSISTANT_FIRST_PROMPT)
        return DEFAULT_ASSISTANT_FIRST_PROMPT

# åŠ è½½é…ç½®å’Œæç¤ºè¯
load_config()
system_prompt = load_system_prompt()
assistant_first_prompt = load_assistant_first_prompt()

# å¯¹è¯å†å²
history = []

# å…¨å±€æ ‡å¿—ï¼Œç”¨äºä¸­æ–­æ¨¡å‹è¾“å‡º
stop_generation = False

# æ¨¡å‹å†å²é‡ç½®
def model_history_restart():
    history.clear()
    # æ·»åŠ ç³»ç»Ÿæç¤ºè¯å’ŒåŠ©æ‰‹çš„ç¬¬ä¸€å¥è¯
    history.append({"role": "system", "content": system_prompt})
    history.append({"role": "assistant", "content": assistant_first_prompt})
    return history

def chat_to_ollama(user_input):  # ä¸ollamaèŠå¤©ï¼Œè¿”å›èŠå¤©è¿­ä»£å™¨
    global stop_generation
    stop_generation = False
    history.append({"role": "user", "content": user_input})
    response = ollama.Client(host=f"http://{configs['host']}:{configs['port']}").chat(
        model=configs['model_name'], stream=True, messages=history, options={
            "temperature": configs['options']['temperature'],
            "num_ctx": configs['options']['num_ctx'],
            "top_k": configs['options']['top_k'],
            "top_p": configs['options']['top_p'],
            "repeat_penalty": configs['options']['repeat_penalty'],
            "seed": configs['options']["seed"] if configs['options']["seed"] >= 0 else random.randint(0, 1000000000)})

    assistant_response = ""
    for chunk in response:
        if stop_generation:
            break
        assistant_response += chunk['message']['content']
        yield assistant_response
    if not stop_generation:
        history.append({"role": "assistant", "content": assistant_response})

def stop_at_exit():  # é€€å‡º
    # å½“ç”¨æˆ·é€€å‡ºåº”ç”¨æ—¶ï¼Œæ‰§è¡Œæ§åˆ¶å°å‘½ä»¤ï¼šollama stop <æ¨¡å‹åç§°>
    os.system(f'ollama stop {configs["model_name"]}')
    print('\n<- æ­£åœ¨é€€å‡º ->\n')
    time.sleep(1.5)

def load_history(file):
    try:
        with open(file.name, 'r', encoding='utf-8') as f:
            loaded_history = json.load(f)
        history.clear()
        history.extend(loaded_history)
        return loaded_history
    except Exception as e:
        print(f"åŠ è½½å†å²å¤±è´¥: {e}")
        return None

def update_config(temperature, top_k, top_p, repeat_penalty, seed):
    configs['options']['temperature'] = temperature
    configs['options']['top_k'] = top_k
    configs['options']['top_p'] = top_p
    configs['options']['repeat_penalty'] = repeat_penalty
    configs['options']['seed'] = seed

def random_seed():
    return random.randint(0, 1000000000)

def stop_generation_fn():
    global stop_generation
    stop_generation = True

# è·å–å†å²æ–‡ä»¶åˆ—è¡¨
def get_history_files():
    history_dir = './history'
    if not os.path.exists(history_dir):
        os.makedirs(history_dir)
    files = os.listdir(history_dir)
    return [f for f in files if f.endswith('.json')]

# è¯»å–å†å²æ–‡ä»¶å¹¶æ›´æ–°èŠå¤©è®°å½•
def load_history_from_dropdown(selected_file):
    if selected_file == "æ— ":
        # å¦‚æœé€‰æ‹©â€œæ— â€ï¼Œåˆ™é‡ç½®å†å²æ•°ç»„å’Œ Chatbot ç»„ä»¶
        return model_history_restart()
    else:
        history_dir = './history'
        filepath = os.path.join(history_dir, f"{selected_file}.json")
        if os.path.exists(filepath):
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    loaded_history = json.load(f)
                history.clear()
                history.extend(loaded_history)
                return loaded_history
            except Exception as e:
                print(f"åŠ è½½å†å²å¤±è´¥: {e}")
        return None

# åˆ·æ–°å†å²æ–‡ä»¶åˆ—è¡¨
def refresh_history_files():
    model_history_restart()  # é‡ç½®å†å²æ•°ç»„
    files = get_history_files()
    # æ·»åŠ é»˜è®¤é€‰é¡¹â€œæ— â€ï¼Œå¹¶ç¡®ä¿å®ƒæ˜¯ç¬¬ä¸€ä¸ªé€‰é¡¹
    return gr.Dropdown(choices=["æ— "] + [os.path.splitext(f)[0] for f in files], value="æ— ")

# ä¿å­˜å†å²æ—¶ä½¿ç”¨å‰ç¼€
def save_history_with_prefix(prefix):
    if not prefix.strip():  # å¦‚æœå‰ç¼€ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼
        prefix = "History"
    # ç¡®ä¿ history ç›®å½•å­˜åœ¨
    history_dir = '.\\history\\'
    if not os.path.exists(history_dir):
        os.makedirs(history_dir)

    # ç”Ÿæˆéšæœºæ–‡ä»¶å
    random_str = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=6))
    current_time = datetime.now().strftime("%Y%m%d%H%M%S")
    filename = f"{prefix}_{current_time}_{random_str}.json"
    filepath = os.path.join(history_dir, filename)

    # ä¿å­˜å†å²åˆ°æ–‡ä»¶
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(history, f, indent=4, ensure_ascii=False)
    return filepath

# æ‰“å¼€å†å²æ–‡ä»¶å¤¹
def open_history_folder():
    history_dir = '.\\history\\'
    if not os.path.exists(history_dir):
        os.makedirs(history_dir)
    # æ‰“å¼€æ–‡ä»¶å¤¹
    if os.name == 'nt':  # Windows
        os.startfile(history_dir)
    elif os.name == 'posix':  # macOS æˆ– Linux
        os.system(f'open "{history_dir}"' if os.uname().sysname == 'Darwin' else f'xdg-open "{history_dir}"')

# Gradioç•Œé¢
with gr.Blocks(
        title=f"ğŸ”¥ å¯¹è¯æœºï¼š{configs['model_name']} ğŸ”¥",
        css=".gradio-container {background-color: #252A34;}"
            ".chatbot {background-color: #08D9D6; overflow: auto;}"
            ".top-panel {display: none;}"
            ".btn-submit {background-color: #FF2E63; height: 95px; max_height: 95px; font-size: 30px;}"
            ".btn-normal {background-color: #08D9D6;}"
            ".btn-refresh {height: 100px;}"
            ".txt-chat-input {height: 150px; max_height: 150px;}"
) as demo:
    # æ ‡é¢˜
    gr.HTML("<h1 align='center' class='normal-text'>ğŸ”¥ Ollama å¯¹è¯æœºå™¨äºº ğŸ”¥</h1>")
    # èŠå¤©ç•Œé¢
    chatbot = gr.Chatbot(type="messages", label=f"{configs['model_name']}ï¼š", value=model_history_restart(),
                         editable="all", height=500,
                         show_copy_button=True, avatar_images=(None, None), resizeable=True,
                         min_height=200)  # åˆå§‹åŒ–æ—¶åŠ è½½åŠ©æ‰‹çš„ç¬¬ä¸€å¥è¯
    with gr.Row():
        msg = gr.Textbox(label="è¾“å…¥æ¶ˆæ¯", container=False, lines=7, max_lines=20,
                         placeholder=">>> è¯´ç‚¹ä»€ä¹ˆå§", scale=6, elem_classes="txt-chat-input")
        # åŠŸèƒ½æŒ‰é’®
        with gr.Column(scale=1):
            submit_btn = gr.Button("æäº¤", variant="primary", scale=1, elem_classes="btn-submit")
            stop_btn = gr.Button("ä¸­æ­¢", scale=1, elem_classes="btn-normal")

    # æ–‡ä»¶ä¿å­˜ç»„ä»¶
    file_save = gr.File(visible=False)

    # å†å²æ¸…å•
    with gr.Accordion("å†å²æ¸…å•", open=False):
        gr.HTML("<p align='left' style='color: #08D9D6;'>â€œå†å²æ¸…å•â€å…è®¸ä½ æŸ¥çœ‹å’Œç®¡ç†ä»¥å‰çš„å¯¹è¯å†å²ã€‚\n"
                "ç‚¹å‡»â€œåˆ·æ–°å†å²è®°å½•â€å¯ä»¥é‡æ–°åŠ è½½å†å²æ¸…å•ï¼Œé€šè¿‡é€‰æ‹©å†å²æ¸…å•æ¥åŠ è½½å†å²ã€‚"
                "å‡¡æŒ‰ä¸‹â€œä¿å­˜å†å²â€ã€â€œåˆ·æ–°å†å²è®°å½•â€éƒ½ä¼šæ¸…é™¤å½“å‰å¯¹è¯å†å²ã€‚</h1>")
        with gr.Row():
            prefix_input = gr.Textbox(label="å†å²æ–‡ä»¶å‰ç¼€", value="HistoryFile", placeholder="è¯·è¾“å…¥ä¿å­˜å†å²æ–‡ä»¶çš„å‰ç¼€",
                                      lines=1, max_lines=1, container=False)
            save_btn = gr.Button("ä¿å­˜å†å²", elem_classes="btn-normal", min_width=15)
            load_btn = gr.UploadButton("è¯»å–å†å²", file_types=[".json"], elem_classes="btn-normal", min_width=15)
            open_folder_btn = gr.Button("æ‰“å¼€å†å²æ–‡ä»¶å¤¹", elem_classes="btn-normal", min_width=15)
        with gr.Row():
            history_dropdown = gr.Dropdown(choices=["æ— "], value="æ— ", label="é€‰æ‹©å†å²æ–‡ä»¶", scale=3)
            refresh_btn = gr.Button("åˆ·æ–°å†å²ç›®å½• & æ¸…é™¤å†å²", elem_classes="btn-refresh", scale=1, min_width=35)

    # æ¨¡å‹é…ç½®
    with gr.Accordion("æ¨¡å‹é…ç½®", open=False):
        temperature = gr.Slider(0.0, 2.0, value=configs['options']['temperature'], label="Temperature",
                                info="temperatureå€¼è¶Šé«˜ï¼Œæ¨¡å‹åˆ›é€ æ€§è¶Šå¼ºï¼›å€¼è¶Šä½ï¼Œæ¨¡å‹ç›¸å¹²æ€§è¶Šå¼ºã€‚")
        top_k = gr.Slider(10, 100, value=configs['options']['top_k'], step=1, label="Top_k",
                          info="top_ké‡‡æ ·ä¼šå½±å“å›ç­”çš„å¤šæ ·åŒ–ç¨‹åº¦ã€‚")
        top_p = gr.Slider(0.5, 0.95, value=configs['options']['top_p'], label="Top_p",
                          info="top_Pç›¸å½“äºtop_Kçš„é˜ˆå€¼ï¼Œä¹Ÿä¼šå½±å“å¤šæ ·åŒ–ç¨‹åº¦ã€‚")
        repeat_penalty = gr.Slider(0.8, 1.5, value=configs['options']['repeat_penalty'], label="Repeat penalty",
                                   info="repeat_penaltyæ˜¯é‡å¤æƒ©ç½šï¼Œèƒ½é¿å…ç”Ÿæˆé‡å¤ä¿¡æ¯ã€‚")
        with gr.Row():
            seed = gr.Number(value=configs['options']['seed'], label="Seed",
                             info="seedæ˜¯ä½¿ç”¨å›ºå®šç§å­ï¼Œ-1ä¸ºä½¿ç”¨éšæœºç§å­ã€‚", scale=5)
            random_seed_btn = gr.Button("éšæœº", scale=1, elem_classes="btn-refresh")


    # äº¤äº’é€»è¾‘
    def respond(user_input, chat_history):
        bot_response = chat_to_ollama(user_input)
        chat_history.append({"role": "user", "content": user_input})  # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°èŠå¤©è®°å½•
        for response in bot_response:
            if len(chat_history) > 0 and chat_history[-1]["role"] == "user":
                chat_history.append({"role": "assistant", "content": response})  # æ·»åŠ åŠ©æ‰‹å“åº”
            else:
                chat_history[-1]["content"] = response  # æ›´æ–°åŠ©æ‰‹å“åº”
            yield chat_history

    # äº¤äº’é€»è¾‘
    submit_btn.click(respond, [msg, chatbot], [chatbot])
    stop_btn.click(stop_generation_fn, None, None)
    save_btn.click(save_history_with_prefix, prefix_input, [file_save]).then(refresh_history_files, None, [history_dropdown])
    load_btn.upload(load_history, load_btn, [chatbot])
    refresh_btn.click(refresh_history_files, None, [history_dropdown]).then(load_history_from_dropdown, history_dropdown, [chatbot])
    history_dropdown.change(load_history_from_dropdown, history_dropdown, [chatbot])
    open_folder_btn.click(open_history_folder, None, None)
    temperature.change(update_config, [temperature, top_k, top_p, repeat_penalty, seed], None)
    top_k.change(update_config, [temperature, top_k, top_p, repeat_penalty, seed], None)
    top_p.change(update_config, [temperature, top_k, top_p, repeat_penalty, seed], None)
    repeat_penalty.change(update_config, [temperature, top_k, top_p, repeat_penalty, seed], None)
    seed.change(update_config, [temperature, top_k, top_p, repeat_penalty, seed], None)
    random_seed_btn.click(random_seed, None, [seed])

    # é¡µé¢åŠ è½½æ—¶æ¸…é™¤å†å²
    demo.load(model_history_restart, None, [chatbot])


# å…¥å£å‡½æ•°
if __name__ == '__main__':
    atexit.register(stop_at_exit)  # æ³¨å†Œé€€å‡º
    # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
    webbrowser.open_new_tab(f"http://{configs['host']}:{configs['uiport']}")  # æ‰“å¼€é»˜è®¤æµè§ˆå™¨çš„æ–°æ ‡ç­¾é¡µ
    # å¯åŠ¨ï¼Œè¿è¡Œåœ¨0.0.0.0æœ¬æœºä¸Šï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ç³»ç»Ÿç¯å¢ƒå˜é‡GRADIO_SERVER_NAMEæ¥æ”¹å˜
    demo.launch(server_name='0.0.0.0', server_port=int(configs['uiport']))
